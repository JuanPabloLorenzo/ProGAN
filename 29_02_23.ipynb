{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Imports\n","\n","This section contains all the installs and imports needed to run the code. "]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:06.145740Z","iopub.status.busy":"2024-02-29T04:21:06.145429Z","iopub.status.idle":"2024-02-29T04:21:19.828024Z","shell.execute_reply":"2024-02-29T04:21:19.827087Z","shell.execute_reply.started":"2024-02-29T04:21:06.145711Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting mtcnn\n","  Downloading mtcnn-0.1.1-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: keras>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from mtcnn) (2.15.0)\n","Requirement already satisfied: opencv-python>=4.1.0 in /opt/conda/lib/python3.10/site-packages (from mtcnn) (4.9.0.80)\n","Requirement already satisfied: numpy>=1.21.2 in /opt/conda/lib/python3.10/site-packages (from opencv-python>=4.1.0->mtcnn) (1.24.4)\n","Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n","\u001b[?25hInstalling collected packages: mtcnn\n","Successfully installed mtcnn-0.1.1\n"]}],"source":["!pip install mtcnn"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:19.830467Z","iopub.status.busy":"2024-02-29T04:21:19.830161Z","iopub.status.idle":"2024-02-29T04:21:32.786217Z","shell.execute_reply":"2024-02-29T04:21:32.785424Z","shell.execute_reply.started":"2024-02-29T04:21:19.830440Z"},"trusted":true},"outputs":[],"source":["from math import sqrt\n","import numpy as np\n","from numpy import load, asarray, zeros, ones, savez_compressed\n","from numpy.random import randn, randint\n","from skimage.transform import resize\n","import tensorflow as tf\n","from tensorflow.keras.optimizers.legacy import Adam\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D, Conv2DTranspose\n","from tensorflow.keras.layers import UpSampling2D, AveragePooling2D, LeakyReLU, Layer, Add\n","from keras.constraints import max_norm\n","from keras.initializers import RandomNormal\n","import mtcnn\n","from mtcnn.mtcnn import MTCNN\n","from keras import backend\n","import matplotlib.pyplot as plt\n","import cv2\n","import os\n","from os import listdir\n","from PIL import Image\n","import cv2"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.791760Z","iopub.status.busy":"2024-02-29T04:21:32.791476Z","iopub.status.idle":"2024-02-29T04:21:32.796755Z","shell.execute_reply":"2024-02-29T04:21:32.795795Z","shell.execute_reply.started":"2024-02-29T04:21:32.791735Z"},"trusted":true},"outputs":[],"source":["learning_rate = 0.001\n","beta1 = 0.0\n","beta2 = 0.99\n","epsilon = 1e-8\n","adam_config = {'learning_rate': learning_rate, 'beta_1': beta1, 'beta_2': beta2, 'epsilon': epsilon}"]},{"cell_type":"markdown","metadata":{},"source":["# Creating the model"]},{"cell_type":"code","execution_count":3,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.798295Z","iopub.status.busy":"2024-02-29T04:21:32.797957Z","iopub.status.idle":"2024-02-29T04:21:32.835142Z","shell.execute_reply":"2024-02-29T04:21:32.834120Z","shell.execute_reply.started":"2024-02-29T04:21:32.798263Z"},"trusted":true},"outputs":[],"source":["# pixel-wise feature vector normalization layer\n","class PixelNormalization(Layer):\n","    # initialize the layer\n","    def __init__(self, **kwargs):\n","        super(PixelNormalization, self).__init__(**kwargs)\n"," \n","    # perform the operation\n","    def call(self, inputs):\n","        # computing pixel values\n","        values = inputs**2.0\n","        mean_values = backend.mean(values, axis=-1, keepdims=True)\n","        mean_values += 1.0e-8\n","        l2 = backend.sqrt(mean_values)\n","        normalized = inputs / l2\n","        return normalized\n"," \n","    # define the output shape of the layer\n","    def compute_output_shape(self, input_shape):\n","        return input_shape"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.836747Z","iopub.status.busy":"2024-02-29T04:21:32.836419Z","iopub.status.idle":"2024-02-29T04:21:32.846310Z","shell.execute_reply":"2024-02-29T04:21:32.845187Z","shell.execute_reply.started":"2024-02-29T04:21:32.836723Z"},"trusted":true},"outputs":[],"source":["# mini-batch standard deviation layer\n","class MinibatchStdev(Layer):\n","    # initialize the layer\n","    def __init__(self, **kwargs):\n","        super(MinibatchStdev, self).__init__(**kwargs)\n"," \n","    # perform the operation\n","    def call(self, inputs):\n","        mean = backend.mean(inputs, axis=0, keepdims=True)\n","        squ_diffs = backend.square(inputs - mean)\n","        mean_sq_diff = backend.mean(squ_diffs, axis=0, keepdims=True)\n","        mean_sq_diff += 1e-8\n","        stdev = backend.sqrt(mean_sq_diff)\n","        \n","        mean_pix = backend.mean(stdev, keepdims=True)\n","        shape = backend.shape(inputs)\n","        output = backend.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n","        \n","        combined = backend.concatenate([inputs, output], axis=-1)\n","        return combined\n"," \n","    # define the output shape of the layer\n","    def compute_output_shape(self, input_shape):\n","        input_shape = list(input_shape)\n","        input_shape[-1] += 1\n","        return tuple(input_shape)"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.847823Z","iopub.status.busy":"2024-02-29T04:21:32.847483Z","iopub.status.idle":"2024-02-29T04:21:32.860781Z","shell.execute_reply":"2024-02-29T04:21:32.860061Z","shell.execute_reply.started":"2024-02-29T04:21:32.847793Z"},"trusted":true},"outputs":[],"source":["# weighted sum output\n","class WeightedSum(Add):\n","    # init with default value\n","    def __init__(self, alpha=0.0, **kwargs):\n","        super(WeightedSum, self).__init__(**kwargs)\n","        self.alpha = backend.variable(alpha, name='ws_alpha')\n"," \n","    # output a weighted sum of inputs\n","    def _merge_function(self, inputs):\n","        # only supports a weighted sum of two inputs\n","        assert (len(inputs) == 2)\n","        # ((1-a) * input1) + (a * input2)\n","        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n","        return output\n","\n","# calculate wasserstein loss\n","def wasserstein_loss(y_true, y_pred):\n","    return backend.mean(y_true * y_pred)"]},{"cell_type":"markdown","metadata":{},"source":["# Model helper functions"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.862002Z","iopub.status.busy":"2024-02-29T04:21:32.861712Z","iopub.status.idle":"2024-02-29T04:21:32.874515Z","shell.execute_reply":"2024-02-29T04:21:32.873603Z","shell.execute_reply.started":"2024-02-29T04:21:32.861970Z"},"trusted":true},"outputs":[],"source":["import tqdm\n","# load dataset\n","def load_images(directory):\n","    faces = list()\n","    for filename in tqdm.tqdm(listdir(directory)):\n","        face = Image.open(directory + filename)\n","        face = asarray(face)\n","        faces.append(face)\n","    \n","    faces = asarray(faces)\n","    faces = faces.astype('float32')\n","    faces = (faces - 127.5) / 127.5\n","    \n","    return faces\n"," \n","# select real samples\n","def generate_real_samples(dataset, n_samples):\n","    ix = randint(0, dataset.shape[0], n_samples)\n","    X = dataset[ix]\n","    y = ones((n_samples, 1))\n","    return X, y\n"," \n","# generate points in latent space as input for the generator\n","def generate_latent_points(latent_dim, n_samples):\n","    x_input = randn(latent_dim * n_samples)\n","    x_input = x_input.reshape(n_samples, latent_dim)\n","    return x_input\n"," \n","# use the generator to generate n fake examples, with class labels\n","def generate_fake_samples(generator, latent_dim, n_samples):\n","    x_input = generate_latent_points(latent_dim, n_samples)\n","    X = generator.predict(x_input, verbose=0)\n","    y = -ones((n_samples, 1))\n","    return X, y\n"," \n","# update the alpha value on each instance of WeightedSum\n","def update_fadein(models, step, n_steps):\n","    alpha = step / float(n_steps - 1)\n","    for model in models:\n","        for layer in model.layers:\n","            if isinstance(layer, WeightedSum):\n","                backend.set_value(layer.alpha, alpha)\n","                \n","# scale images to preferred size\n","def scale_dataset(images, new_shape):\n","    images_list = list()\n","    for image in images:\n","        new_image = resize(image, new_shape, 0)\n","        images_list.append(new_image)\n","    return asarray(images_list)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.876288Z","iopub.status.busy":"2024-02-29T04:21:32.875810Z","iopub.status.idle":"2024-02-29T04:21:32.888630Z","shell.execute_reply":"2024-02-29T04:21:32.887799Z","shell.execute_reply.started":"2024-02-29T04:21:32.876258Z"},"trusted":true},"outputs":[],"source":["# Create a equalized learning rate layer that inherits from the Conv2D layer\n","class EqualizedConv2D(Conv2D):\n","    def __init__(self, *args, **kwargs):\n","        kwargs['kernel_initializer'] = kwargs.get('kernel_initializer', RandomNormal(0, 1))\n","        super(EqualizedConv2D, self).__init__(*args, **kwargs)\n"," \n","    def build(self, input_shape):\n","        super(EqualizedConv2D, self).build(input_shape)\n","        input_channels = input_shape[-1]\n","        kernel_size = self.kernel_size[0]\n","        self.lr_multiplier = (2 / (input_channels * (kernel_size ** 2))) ** 0.5\n"," \n","    # apply the learning rate multiplier\n","    def call(self, inputs):\n","        # Scale the weights without permanently modifying them\n","        scaled_weights = self.lr_multiplier * self.kernel\n","        outputs = self.convolution_op(inputs, scaled_weights)\n","        if self.use_bias:\n","            outputs = tf.nn.bias_add(outputs, self.bias)\n","        if self.activation is not None:\n","            return self.activation(outputs)\n","        return outputs\n","    \n","# Create a equalized learning rate layer that inherits from the Dense layer\n","class EqualizedDense(Dense):\n","    def __init__(self, *args, **kwargs):\n","        kwargs['kernel_initializer'] = kwargs.get('kernel_initializer', RandomNormal(0, 1))\n","        super(EqualizedDense, self).__init__(*args, **kwargs)\n"," \n","    def build(self, input_shape):\n","        super(EqualizedDense, self).build(input_shape)\n","        input_channels = input_shape[-1]\n","        self.lr_multiplier = (2 / input_channels) ** 0.5\n"," \n","    # apply the learning rate multiplier\n","    def call(self, inputs):\n","        # Scale the weights without permanently modifying them\n","        scaled_weights = self.lr_multiplier * self.kernel\n","        outputs = tf.matmul(inputs, scaled_weights)\n","        if self.use_bias:\n","            outputs = backend.bias_add(outputs, self.bias)\n","        if self.activation is not None:\n","            return self.activation(outputs)\n","        return outputs"]},{"cell_type":"markdown","metadata":{},"source":["# Model creation"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.891650Z","iopub.status.busy":"2024-02-29T04:21:32.891385Z","iopub.status.idle":"2024-02-29T04:21:32.900853Z","shell.execute_reply":"2024-02-29T04:21:32.899947Z","shell.execute_reply.started":"2024-02-29T04:21:32.891625Z"},"trusted":true},"outputs":[],"source":["# adding a generator block\n","def add_generator_block(old_model, filter_count, channels):\n","    block_end = old_model.layers[-2].output\n","    \n","    # upsample, and define new block\n","    upsampling = UpSampling2D()(block_end)\n","    g = EqualizedConv2D(filter_count, (3,3), padding='same')(upsampling)\n","    g = PixelNormalization()(g)\n","    g = LeakyReLU(alpha=0.2)(g)\n","    g = EqualizedConv2D(filter_count, (3,3), padding='same')(g)\n","    g = PixelNormalization()(g)\n","    g = LeakyReLU(alpha=0.2)(g)\n","    \n","    out_image = EqualizedConv2D(channels, (1,1), padding='same')(g)\n","    model1 = Model(old_model.input, out_image)\n","    out_old = old_model.layers[-1]\n","    out_image2 = out_old(upsampling)\n","    \n","    merged = WeightedSum()([out_image2, out_image])\n","    model2 = Model(old_model.input, merged)\n","    return [model1, model2]"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.902273Z","iopub.status.busy":"2024-02-29T04:21:32.901903Z","iopub.status.idle":"2024-02-29T04:21:32.915127Z","shell.execute_reply":"2024-02-29T04:21:32.914286Z","shell.execute_reply.started":"2024-02-29T04:21:32.902202Z"},"trusted":true},"outputs":[],"source":["# define generator models\n","def define_generator(latent_dim, n_blocks, initial_filter_count, in_dim=4, channels=3):\n","    model_list = list()\n","    \n","    in_latent = Input(shape=(latent_dim,))\n","    g = EqualizedDense(initial_filter_count * in_dim * in_dim)(in_latent)\n","    g = Reshape((in_dim, in_dim, initial_filter_count))(g)\n","    \n","    # conv 4x4, input block\n","    g = EqualizedConv2D(initial_filter_count, (4,4), padding='same')(g)\n","    g = PixelNormalization()(g)\n","    g = LeakyReLU(alpha=0.2)(g)\n","    \n","    # conv 3x3\n","    g = EqualizedConv2D(initial_filter_count, (3,3), padding='same')(g)\n","    g = PixelNormalization()(g)\n","    g = LeakyReLU(alpha=0.2)(g)\n","    \n","    # conv 1x1, output block\n","    out_image = EqualizedConv2D(channels, (1,1), padding='same')(g)\n","    model = Model(in_latent, out_image)\n","    model_list.append([model, model])\n","    \n","    for i in range(1, n_blocks):\n","        old_model = model_list[i - 1][0]\n","        models = add_generator_block(old_model, initial_filter_count, channels)# // (2 ** i))\n","        model_list.append(models)\n","        \n","    return model_list"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.916902Z","iopub.status.busy":"2024-02-29T04:21:32.916351Z","iopub.status.idle":"2024-02-29T04:21:32.927580Z","shell.execute_reply":"2024-02-29T04:21:32.926769Z","shell.execute_reply.started":"2024-02-29T04:21:32.916870Z"},"trusted":true},"outputs":[],"source":["# adding a discriminator block\n","def add_discriminator_block(old_model, filter_count, n_input_layers=3):\n","    in_shape = list(old_model.input.shape)\n","    \n","    # define new input shape as double the size\n","    input_shape = (in_shape[-2]*2, in_shape[-2]*2, in_shape[-1])\n","    in_image = Input(shape=input_shape)\n","    \n","    # define new input processing layer\n","    d = EqualizedConv2D(filter_count, (1,1), padding='same')(in_image)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    \n","    # define new block\n","    d = EqualizedConv2D(filter_count, (3, 3), padding='same')(d)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    # d = Conv2D(filter_count * 2, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n","    d = EqualizedConv2D(filter_count, (3, 3), strides=2, padding='same')(d)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    # d = AveragePooling2D()(d)\n","    block_new = d\n","    \n","    # skip the input, 1x1 and activation for the old model\n","    for i in range(n_input_layers, len(old_model.layers)):\n","        d = old_model.layers[i](d)\n","    model1 = Model(in_image, d)\n","    \n","    model1.compile(loss=wasserstein_loss, optimizer=Adam(**adam_config))\n","    \n","    downsample = AveragePooling2D()(in_image)\n","    \n","    block_old = old_model.layers[1](downsample)\n","    block_old = old_model.layers[2](block_old)\n","    d = WeightedSum()([block_old, block_new])\n","    \n","    for i in range(n_input_layers, len(old_model.layers)):\n","        d = old_model.layers[i](d)\n","        \n","    model2 = Model(in_image, d)\n","    \n","    model2.compile(loss=wasserstein_loss, optimizer=Adam(**adam_config))\n","    return [model1, model2]"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.928857Z","iopub.status.busy":"2024-02-29T04:21:32.928565Z","iopub.status.idle":"2024-02-29T04:21:32.940698Z","shell.execute_reply":"2024-02-29T04:21:32.939948Z","shell.execute_reply.started":"2024-02-29T04:21:32.928835Z"},"trusted":true},"outputs":[],"source":["# define the discriminator models for each image resolution\n","def define_discriminator(n_blocks, initial_filter_count, input_shape=(4,4,3)):\n","    model_list = list()\n","    in_image = Input(shape=input_shape)\n","    \n","    d = EqualizedConv2D(initial_filter_count, (1, 1), padding='same')(in_image)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    d = MinibatchStdev()(d)\n","    \n","    d = EqualizedConv2D(initial_filter_count, (3, 3), padding='same')(d)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    d = EqualizedConv2D(initial_filter_count, (4, 4), padding='same')(d)\n","    d = LeakyReLU(alpha=0.2)(d)\n","    \n","    d = Flatten()(d)\n","    out_class = EqualizedDense(1)(d)\n","    \n","    model = Model(in_image, out_class)\n","    model.compile(loss=wasserstein_loss, optimizer=Adam(**adam_config))\n","    model_list.append([model, model])\n","    \n","    for i in range(1, n_blocks):\n","        old_model = model_list[i - 1][0]\n","        models = add_discriminator_block(old_model, initial_filter_count)# / (2 ** i))\n","        model_list.append(models)\n","        \n","    return model_list"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.941904Z","iopub.status.busy":"2024-02-29T04:21:32.941636Z","iopub.status.idle":"2024-02-29T04:21:32.954476Z","shell.execute_reply":"2024-02-29T04:21:32.953577Z","shell.execute_reply.started":"2024-02-29T04:21:32.941884Z"},"trusted":true},"outputs":[],"source":["# define composite models for training generators via discriminators\n","\n","def define_composite(discriminators, generators):\n","    model_list = list()\n","    # create composite models\n","    for i in range(len(discriminators)):\n","        g_models, d_models = generators[i], discriminators[i]\n","        # straight-through model\n","        d_models[0].trainable = False\n","        model1 = Sequential()\n","        model1.add(g_models[0])\n","        model1.add(d_models[0])\n","        model1.compile(loss=wasserstein_loss, optimizer=Adam(**adam_config))\n","        # fade-in model\n","        d_models[1].trainable = False\n","        model2 = Sequential()\n","        model2.add(g_models[1])\n","        model2.add(d_models[1])\n","        model2.compile(loss=wasserstein_loss, optimizer=Adam(**adam_config))\n","        # store\n","        model_list.append([model1, model2])\n","    return model_list"]},{"cell_type":"markdown","metadata":{},"source":["# Create training block"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:30:19.615238Z","iopub.status.busy":"2024-02-29T04:30:19.614850Z","iopub.status.idle":"2024-02-29T04:30:19.633472Z","shell.execute_reply":"2024-02-29T04:30:19.632362Z","shell.execute_reply.started":"2024-02-29T04:30:19.615205Z"},"trusted":true},"outputs":[],"source":["# train a generator and discriminator\n","def train_epochs(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein, critic_steps):\n","    bat_per_epo = int(dataset.shape[0] / n_batch)\n","    n_steps = bat_per_epo * n_epochs\n","    half_batch = int(n_batch / 2)\n","    d_loss1_avg = 0\n","    d_loss2_avg = 0\n","    g_loss_avg = 0\n","    \n","    for i in range(n_steps):\n","        # update alpha for all WeightedSum layers when fading in new blocks\n","        if fadein:\n","            update_fadein([g_model, d_model, gan_model], i, n_steps)\n","        \n","        # prepare real and fake samples\n","        X_real, y_real = generate_real_samples(dataset, half_batch)\n","        \n","        for _ in range(critic_steps):\n","            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n","            d_loss1 = d_model.train_on_batch(X_real, y_real)\n","            d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n","        \n","            d_loss1_avg += d_loss1/critic_steps\n","            d_loss2_avg += d_loss2/critic_steps\n","        \n","        # update the generator via the discriminator's error\n","        z_input = generate_latent_points(latent_dim, n_batch)\n","        y_real2 = ones((n_batch, 1))\n","        g_loss = gan_model.train_on_batch(z_input, y_real2)\n","        g_loss_avg += g_loss\n","        \n","        if i % 100 == 0:\n","            print('Step:%d | Avg Loss: d_loss_real=%.3f, d_loss_fake=%.3f g=%.3f' % (i+1, d_loss1_avg/100, d_loss2_avg/100, g_loss_avg/100))\n","            d_loss1_avg = 0\n","            d_loss2_avg = 0\n","            g_loss_avg = 0\n","        \n","        if i % 1000 == 0:\n","            # Plot some samples\n","            X, _ = generate_fake_samples(g_model, latent_dim, 12)\n","            X = (X - X.min()) / (X.max() - X.min())\n","            \n","            plt.figure(figsize=(8, 3))\n","            for i in range(12):\n","                plt.subplot(2, 6, 1 + i)\n","                plt.axis('off')\n","                img_show = X[i]\n","                plt.imshow(img_show)\n","                \n","            plt.show()\n","            \n","        \n","# train the generator and discriminator\n","def train(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch, critic_steps=1):\n","    g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n","    gen_shape = g_normal.output_shape\n","    scaled_data = scale_dataset(dataset, gen_shape[1:])\n","    print('Scaled Data', scaled_data.shape)\n","\n","    # train normal or straight-through models\n","    train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[0], n_batch[0], False, critic_steps)\n","    summarize_performance('tuned', g_normal, d_normal, latent_dim)\n","    \n","    # process each level of growth\n","    for i in range(1, len(g_models)):\n","        # retrieve models for this level of growth\n","        [g_normal, g_fadein] = g_models[i]\n","        [d_normal, d_fadein] = d_models[i]\n","        [gan_normal, gan_fadein] = gan_models[i]\n","        \n","        # scale dataset to appropriate size\n","        gen_shape = g_normal.output_shape\n","        scaled_data = scale_dataset(dataset, gen_shape[1:])\n","        print('Scaled Data', scaled_data.shape)\n","        \n","        # train fade-in models for next level of growth\n","        train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein[i], n_batch[i], True, critic_steps)\n","        summarize_performance('faded', g_fadein, d_fadein, latent_dim)\n","        \n","        # train normal or straight-through models\n","        train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[i], n_batch[i], False, critic_steps)\n","        summarize_performance('tuned', g_normal, d_normal, latent_dim)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:30:19.723238Z","iopub.status.busy":"2024-02-29T04:30:19.722609Z","iopub.status.idle":"2024-02-29T04:30:19.731527Z","shell.execute_reply":"2024-02-29T04:30:19.730624Z","shell.execute_reply.started":"2024-02-29T04:30:19.723210Z"},"trusted":true},"outputs":[],"source":["# generate samples and save as a plot and save the model\n","def summarize_performance(status, g_model, d_model, latent_dim, n_samples=25):\n","    gen_shape = g_model.output_shape\n","    name = '%03dx%03d-%s' % (gen_shape[1], gen_shape[2], status)\n","    \n","    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n","    X = (X - X.min()) / (X.max() - X.min())\n","    \n","    square = int(sqrt(n_samples))\n","    for i in range(n_samples):\n","        plt.subplot(square, square, 1 + i)\n","        plt.axis('off')\n","        img_show = X[i]\n","        plt.imshow(img_show)\n","        \n","    # save plot to file\n","    if not os.path.exists('plots'):\n","        os.makedirs('plots')\n","    plot_filename = 'plots/plot_%s.png' % (name)\n","    plt.savefig(plot_filename)\n","    plt.close()\n","    \n","    if not os.path.exists('models'):\n","        os.makedirs('models')\n","    g_model_filename = 'models/model_%s.h5' % (name)\n","    g_model.save(g_model_filename)\n","    d_model_filename = 'models/d_model_%s.h5' % (name)\n","    d_model.save(d_model_filename)\n","    print('>Saved: %s, %s and %s' % (plot_filename, g_model_filename, d_model_filename))"]},{"cell_type":"markdown","metadata":{},"source":["# Run training"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:22:46.323849Z","iopub.status.busy":"2024-02-29T04:22:46.323501Z","iopub.status.idle":"2024-02-29T04:28:28.567396Z","shell.execute_reply":"2024-02-29T04:28:28.566385Z","shell.execute_reply.started":"2024-02-29T04:22:46.323821Z"},"trusted":true},"outputs":[],"source":["# Load all the images of face_images_32x32\n","directory = '/kaggle/input/ffhq-32x32/face_images_32x32/'\n","#dataset = load_images(directory)\n","\n","#dataset = dataset[:, :, :, :3]"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:30:23.672169Z","iopub.status.busy":"2024-02-29T04:30:23.671452Z","iopub.status.idle":"2024-02-29T04:30:25.972240Z","shell.execute_reply":"2024-02-29T04:30:25.971471Z","shell.execute_reply.started":"2024-02-29T04:30:23.672124Z"},"trusted":true},"outputs":[],"source":["n_blocks = 4\n","initial_filter_count = 128\n","latent_dim = 40\n","\n","d_models = define_discriminator(n_blocks, initial_filter_count, input_shape=(4,4,3))\n","g_models = define_generator(latent_dim, n_blocks, initial_filter_count, channels=3)\n","gan_models = define_composite(d_models, g_models)\n","\n","n_batch = [16, 16, 16, 16]\n","n_epochs = [1, 2, 5, 10]\n","\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_12\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_5 (InputLayer)        [(None, 40)]              0         \n","                                                                 \n"," equalized_dense_1 (Equaliz  (None, 2048)              83968     \n"," edDense)                                                        \n","                                                                 \n"," reshape (Reshape)           (None, 4, 4, 128)         0         \n","                                                                 \n"," equalized_conv2d_12 (Equal  (None, 4, 4, 128)         262272    \n"," izedConv2D)                                                     \n","                                                                 \n"," pixel_normalization (Pixel  (None, 4, 4, 128)         0         \n"," Normalization)                                                  \n","                                                                 \n"," leaky_re_lu_12 (LeakyReLU)  (None, 4, 4, 128)         0         \n","                                                                 \n"," equalized_conv2d_13 (Equal  (None, 4, 4, 128)         147584    \n"," izedConv2D)                                                     \n","                                                                 \n"," pixel_normalization_1 (Pix  (None, 4, 4, 128)         0         \n"," elNormalization)                                                \n","                                                                 \n"," leaky_re_lu_13 (LeakyReLU)  (None, 4, 4, 128)         0         \n","                                                                 \n"," up_sampling2d (UpSampling2  (None, 8, 8, 128)         0         \n"," D)                                                              \n","                                                                 \n"," equalized_conv2d_15 (Equal  (None, 8, 8, 128)         147584    \n"," izedConv2D)                                                     \n","                                                                 \n"," pixel_normalization_2 (Pix  (None, 8, 8, 128)         0         \n"," elNormalization)                                                \n","                                                                 \n"," leaky_re_lu_14 (LeakyReLU)  (None, 8, 8, 128)         0         \n","                                                                 \n"," equalized_conv2d_16 (Equal  (None, 8, 8, 128)         147584    \n"," izedConv2D)                                                     \n","                                                                 \n"," pixel_normalization_3 (Pix  (None, 8, 8, 128)         0         \n"," elNormalization)                                                \n","                                                                 \n"," leaky_re_lu_15 (LeakyReLU)  (None, 8, 8, 128)         0         \n","                                                                 \n"," up_sampling2d_1 (UpSamplin  (None, 16, 16, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," equalized_conv2d_18 (Equal  (None, 16, 16, 128)       147584    \n"," izedConv2D)                                                     \n","                                                                 \n"," pixel_normalization_4 (Pix  (None, 16, 16, 128)       0         \n"," elNormalization)                                                \n","                                                                 \n"," leaky_re_lu_16 (LeakyReLU)  (None, 16, 16, 128)       0         \n","                                                                 \n"," equalized_conv2d_19 (Equal  (None, 16, 16, 128)       147584    \n"," izedConv2D)                                                     \n","                                                                 \n"," pixel_normalization_5 (Pix  (None, 16, 16, 128)       0         \n"," elNormalization)                                                \n","                                                                 \n"," leaky_re_lu_17 (LeakyReLU)  (None, 16, 16, 128)       0         \n","                                                                 \n"," up_sampling2d_2 (UpSamplin  (None, 32, 32, 128)       0         \n"," g2D)                                                            \n","                                                                 \n"," equalized_conv2d_21 (Equal  (None, 32, 32, 128)       147584    \n"," izedConv2D)                                                     \n","                                                                 \n"," pixel_normalization_6 (Pix  (None, 32, 32, 128)       0         \n"," elNormalization)                                                \n","                                                                 \n"," leaky_re_lu_18 (LeakyReLU)  (None, 32, 32, 128)       0         \n","                                                                 \n"," equalized_conv2d_22 (Equal  (None, 32, 32, 128)       147584    \n"," izedConv2D)                                                     \n","                                                                 \n"," pixel_normalization_7 (Pix  (None, 32, 32, 128)       0         \n"," elNormalization)                                                \n","                                                                 \n"," leaky_re_lu_19 (LeakyReLU)  (None, 32, 32, 128)       0         \n","                                                                 \n"," equalized_conv2d_23 (Equal  (None, 32, 32, 3)         387       \n"," izedConv2D)                                                     \n","                                                                 \n","=================================================================\n","Total params: 1379715 (5.26 MB)\n","Trainable params: 1379715 (5.26 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}],"source":["g_models[-1][0].summary()"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"model_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_4 (InputLayer)        [(None, 32, 32, 3)]       0         \n","                                                                 \n"," equalized_conv2d_9 (Equali  (None, 32, 32, 128)       512       \n"," zedConv2D)                                                      \n","                                                                 \n"," leaky_re_lu_9 (LeakyReLU)   (None, 32, 32, 128)       0         \n","                                                                 \n"," equalized_conv2d_10 (Equal  (None, 32, 32, 128)       147584    \n"," izedConv2D)                                                     \n","                                                                 \n"," leaky_re_lu_10 (LeakyReLU)  (None, 32, 32, 128)       0         \n","                                                                 \n"," equalized_conv2d_11 (Equal  (None, 16, 16, 128)       147584    \n"," izedConv2D)                                                     \n","                                                                 \n"," leaky_re_lu_11 (LeakyReLU)  (None, 16, 16, 128)       0         \n","                                                                 \n"," equalized_conv2d_7 (Equali  (None, 16, 16, 128)       147584    \n"," zedConv2D)                                                      \n","                                                                 \n"," leaky_re_lu_7 (LeakyReLU)   (None, 16, 16, 128)       0         \n","                                                                 \n"," equalized_conv2d_8 (Equali  (None, 8, 8, 128)         147584    \n"," zedConv2D)                                                      \n","                                                                 \n"," leaky_re_lu_8 (LeakyReLU)   (None, 8, 8, 128)         0         \n","                                                                 \n"," equalized_conv2d_4 (Equali  (None, 8, 8, 128)         147584    \n"," zedConv2D)                                                      \n","                                                                 \n"," leaky_re_lu_4 (LeakyReLU)   (None, 8, 8, 128)         0         \n","                                                                 \n"," equalized_conv2d_5 (Equali  (None, 4, 4, 128)         147584    \n"," zedConv2D)                                                      \n","                                                                 \n"," leaky_re_lu_5 (LeakyReLU)   (None, 4, 4, 128)         0         \n","                                                                 \n"," minibatch_stdev (Minibatch  (None, 4, 4, 129)         0         \n"," Stdev)                                                          \n","                                                                 \n"," equalized_conv2d_1 (Equali  (None, 4, 4, 128)         148736    \n"," zedConv2D)                                                      \n","                                                                 \n"," leaky_re_lu_1 (LeakyReLU)   (None, 4, 4, 128)         0         \n","                                                                 \n"," equalized_conv2d_2 (Equali  (None, 4, 4, 128)         262272    \n"," zedConv2D)                                                      \n","                                                                 \n"," leaky_re_lu_2 (LeakyReLU)   (None, 4, 4, 128)         0         \n","                                                                 \n"," flatten (Flatten)           (None, 2048)              0         \n","                                                                 \n"," equalized_dense (Equalized  (None, 1)                 2049      \n"," Dense)                                                          \n","                                                                 \n","=================================================================\n","Total params: 1299073 (4.96 MB)\n","Trainable params: 0 (0.00 Byte)\n","Non-trainable params: 1299073 (4.96 MB)\n","_________________________________________________________________\n"]}],"source":["d_models[-1][0].summary()"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:32:13.343772Z","iopub.status.busy":"2024-02-29T04:32:13.342918Z","iopub.status.idle":"2024-02-29T04:35:56.781903Z","shell.execute_reply":"2024-02-29T04:35:56.780335Z","shell.execute_reply.started":"2024-02-29T04:32:13.343726Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Scaled Data (50000, 4, 4, 3)\n","Step:1 | Avg Loss: d_loss_real=0.007, d_loss_fake=0.010 g=-0.007\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 800x300 with 12 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step:101 | Avg Loss: d_loss_real=-1.363, d_loss_fake=1.484 g=-1.127\n","Step:201 | Avg Loss: d_loss_real=0.182, d_loss_fake=0.090 g=0.340\n","Step:301 | Avg Loss: d_loss_real=-1.216, d_loss_fake=1.391 g=-1.086\n","Step:401 | Avg Loss: d_loss_real=-0.526, d_loss_fake=0.496 g=-0.037\n","Step:501 | Avg Loss: d_loss_real=-0.608, d_loss_fake=0.796 g=-0.462\n","Step:601 | Avg Loss: d_loss_real=-1.180, d_loss_fake=1.212 g=-0.828\n","Step:701 | Avg Loss: d_loss_real=-1.111, d_loss_fake=1.226 g=-0.985\n","Step:801 | Avg Loss: d_loss_real=-0.650, d_loss_fake=0.825 g=-0.539\n","Step:901 | Avg Loss: d_loss_real=-0.877, d_loss_fake=0.884 g=-0.659\n","Step:1001 | Avg Loss: d_loss_real=-0.644, d_loss_fake=0.819 g=-0.650\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 800x300 with 12 Axes>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Step:1101 | Avg Loss: d_loss_real=-0.809, d_loss_fake=0.894 g=-0.691\n","Step:1201 | Avg Loss: d_loss_real=-0.779, d_loss_fake=0.810 g=-0.685\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[26], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_models\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[22], line 61\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch, critic_steps)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mScaled Data\u001b[39m\u001b[38;5;124m'\u001b[39m, scaled_data\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# train normal or straight-through models\u001b[39;00m\n\u001b[0;32m---> 61\u001b[0m \u001b[43mtrain_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mg_normal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_normal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgan_normal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscaled_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43me_norm\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_batch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcritic_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m summarize_performance(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtuned\u001b[39m\u001b[38;5;124m'\u001b[39m, g_normal, d_normal, latent_dim)\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# process each level of growth\u001b[39;00m\n","Cell \u001b[0;32mIn[22], line 20\u001b[0m, in \u001b[0;36mtrain_epochs\u001b[0;34m(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein, critic_steps)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(critic_steps):\n\u001b[1;32m     19\u001b[0m     X_fake, y_fake \u001b[38;5;241m=\u001b[39m generate_fake_samples(g_model, latent_dim, half_batch)\n\u001b[0;32m---> 20\u001b[0m     d_loss1 \u001b[38;5;241m=\u001b[39m \u001b[43md_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_on_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_real\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_real\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     d_loss2 \u001b[38;5;241m=\u001b[39m d_model\u001b[38;5;241m.\u001b[39mtrain_on_batch(X_fake, y_fake)\n\u001b[1;32m     23\u001b[0m     d_loss1_avg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m d_loss1\u001b[38;5;241m/\u001b[39mcritic_steps\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:2783\u001b[0m, in \u001b[0;36mModel.train_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   2779\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_metrics()\n\u001b[1;32m   2780\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdistribute_strategy\u001b[38;5;241m.\u001b[39mscope(), training_utils\u001b[38;5;241m.\u001b[39mRespectCompiledTrainableState(  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[1;32m   2781\u001b[0m     \u001b[38;5;28mself\u001b[39m\n\u001b[1;32m   2782\u001b[0m ):\n\u001b[0;32m-> 2783\u001b[0m     iterator \u001b[38;5;241m=\u001b[39m \u001b[43mdata_adapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_batch_iterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2784\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute_strategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\n\u001b[1;32m   2785\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2786\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmake_train_function()\n\u001b[1;32m   2787\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_function(iterator)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1932\u001b[0m, in \u001b[0;36msingle_batch_iterator\u001b[0;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msingle_batch_iterator\u001b[39m(\n\u001b[1;32m   1929\u001b[0m     strategy, x, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1930\u001b[0m ):\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a single-batch dataset.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1932\u001b[0m     x, y, sample_weight \u001b[38;5;241m=\u001b[39m \u001b[43m_process_tensorlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1933\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1934\u001b[0m         data \u001b[38;5;241m=\u001b[39m (x,)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/data_adapter.py:1163\u001b[0m, in \u001b[0;36m_process_tensorlike\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _scipy_sparse_to_sparse_tensor(x)\n\u001b[1;32m   1161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m-> 1163\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_convert_single_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39m__internal__\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mlist_to_tuple(inputs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest.py:631\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;129m@tf_export\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnest.map_structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    546\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_structure\u001b[39m(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    547\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    548\u001b[0m \n\u001b[1;32m    549\u001b[0m \u001b[38;5;124;03m  Refer to [tf.nest](https://www.tensorflow.org/api_docs/python/tf/nest)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;124;03m    ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_structure\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mModality\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCORE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1066\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(modality, func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Creates a new structure by applying `func` to each atom in `structure`.\u001b[39;00m\n\u001b[1;32m    970\u001b[0m \n\u001b[1;32m    971\u001b[0m \u001b[38;5;124;03m- For Modality.CORE: Refer to\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m  ValueError: If wrong keyword arguments are provided.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mCORE:\n\u001b[0;32m-> 1066\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_map_structure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m modality \u001b[38;5;241m==\u001b[39m Modality\u001b[38;5;241m.\u001b[39mDATA:\n\u001b[1;32m   1068\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_data_map_structure(func, \u001b[38;5;241m*\u001b[39mstructure, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:1104\u001b[0m, in \u001b[0;36m_tf_core_map_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m   1101\u001b[0m flat_structure \u001b[38;5;241m=\u001b[39m (_tf_core_flatten(s, expand_composites) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m structure)\n\u001b[1;32m   1102\u001b[0m entries \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mflat_structure)\n\u001b[0;32m-> 1104\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_core_pack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1105\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1106\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mentries\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1107\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexpand_composites\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1108\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:920\u001b[0m, in \u001b[0;36m_tf_core_pack_sequence_as\u001b[0;34m(structure, flat_sequence, expand_composites, sequence_fn)\u001b[0m\n\u001b[1;32m    913\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(flat_structure) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(flat_sequence):\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;66;03m# pylint: disable=raise-missing-from\u001b[39;00m\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    916\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not pack sequence. Structure had \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m atoms, but \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    917\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflat_sequence had \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m items.  Structure: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, flat_sequence: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    918\u001b[0m         \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mlen\u001b[39m(flat_structure), \u001b[38;5;28mlen\u001b[39m(flat_sequence), structure, flat_sequence)\n\u001b[1;32m    919\u001b[0m     )\n\u001b[0;32m--> 920\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msequence_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpacked\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/nest_util.py:245\u001b[0m, in \u001b[0;36msequence_like\u001b[0;34m(instance, args)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(instance, _wrapt\u001b[38;5;241m.\u001b[39mObjectProxy):\n\u001b[1;32m    242\u001b[0m   \u001b[38;5;66;03m# For object proxies, first create the underlying type and then re-wrap it\u001b[39;00m\n\u001b[1;32m    243\u001b[0m   \u001b[38;5;66;03m# in the proxy type.\u001b[39;00m\n\u001b[1;32m    244\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(instance)(sequence_like(instance\u001b[38;5;241m.\u001b[39m__wrapped__, args))\n\u001b[0;32m--> 245\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCustomNestProtocol\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    246\u001b[0m   metadata \u001b[38;5;241m=\u001b[39m instance\u001b[38;5;241m.\u001b[39m__tf_flatten__()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    247\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m instance\u001b[38;5;241m.\u001b[39m__tf_unflatten__(metadata, \u001b[38;5;28mtuple\u001b[39m(args))\n","File \u001b[0;32m/opt/conda/lib/python3.10/typing.py:1503\u001b[0m, in \u001b[0;36m_ProtocolMeta.__instancecheck__\u001b[0;34m(cls, instance)\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1494\u001b[0m     \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_protocol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_runtime_protocol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m   1496\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m _allow_reckless_class_checks(depth\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m   1497\u001b[0m ):\n\u001b[1;32m   1498\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstance and class checks can only be used with\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1499\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m @runtime_checkable protocols\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mcls\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_is_protocol\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m         _is_callable_members_only(\u001b[38;5;28mcls\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m-> 1503\u001b[0m         \u001b[38;5;28;43missubclass\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m)\u001b[49m):\n\u001b[1;32m   1504\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_protocol:\n","File \u001b[0;32m/opt/conda/lib/python3.10/abc.py:123\u001b[0m, in \u001b[0;36mABCMeta.__subclasscheck__\u001b[0;34m(cls, subclass)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__subclasscheck__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, subclass):\n\u001b[1;32m    122\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Override for issubclass(subclass, cls).\"\"\"\u001b[39;00m\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_abc_subclasscheck\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubclass\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["train(g_models, d_models, gan_models, dataset, latent_dim, n_epochs, n_epochs, n_batch, critic_steps=2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4388117,"sourceId":7534747,"sourceType":"datasetVersion"},{"datasetId":4390550,"sourceId":7540022,"sourceType":"datasetVersion"},{"datasetId":4481234,"sourceId":7680951,"sourceType":"datasetVersion"}],"dockerImageVersionId":30648,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
