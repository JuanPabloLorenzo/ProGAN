{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7534747,"sourceType":"datasetVersion","datasetId":4388117},{"sourceId":7540022,"sourceType":"datasetVersion","datasetId":4390550},{"sourceId":7680951,"sourceType":"datasetVersion","datasetId":4481234}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports\n\nThis section contains all the installs and imports needed to run the code. ","metadata":{}},{"cell_type":"code","source":"!pip install mtcnn","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:06.145740Z","iopub.status.busy":"2024-02-29T04:21:06.145429Z","iopub.status.idle":"2024-02-29T04:21:19.828024Z","shell.execute_reply":"2024-02-29T04:21:19.827087Z","shell.execute_reply.started":"2024-02-29T04:21:06.145711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from math import sqrt\nimport numpy as np\nfrom numpy import load, asarray, zeros, ones, savez_compressed\nfrom numpy.random import randn, randint\nfrom skimage.transform import resize\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers.legacy import Adam\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Reshape, Conv2D, Conv2DTranspose\nfrom tensorflow.keras.layers import UpSampling2D, AveragePooling2D, LeakyReLU, Layer, Add\nfrom keras.constraints import max_norm\nfrom keras.initializers import RandomNormal\nimport mtcnn\nfrom mtcnn.mtcnn import MTCNN\nfrom keras import backend\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\nfrom os import listdir\nfrom PIL import Image\nimport cv2","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:19.830467Z","iopub.status.busy":"2024-02-29T04:21:19.830161Z","iopub.status.idle":"2024-02-29T04:21:32.786217Z","shell.execute_reply":"2024-02-29T04:21:32.785424Z","shell.execute_reply.started":"2024-02-29T04:21:19.830440Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learning_rate = 0.0015\nbeta1 = 0.0\nbeta2 = 0.99\nepsilon = 1e-8\nadam_config = {'learning_rate': learning_rate, 'beta_1': beta1, 'beta_2': beta2, 'epsilon': epsilon}","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.791760Z","iopub.status.busy":"2024-02-29T04:21:32.791476Z","iopub.status.idle":"2024-02-29T04:21:32.796755Z","shell.execute_reply":"2024-02-29T04:21:32.795795Z","shell.execute_reply.started":"2024-02-29T04:21:32.791735Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating the model","metadata":{}},{"cell_type":"code","source":"# pixel-wise feature vector normalization layer\nclass PixelNormalization(Layer):\n    # initialize the layer\n    def __init__(self, **kwargs):\n        super(PixelNormalization, self).__init__(**kwargs)\n \n    # perform the operation\n    def call(self, inputs):\n        # computing pixel values\n        values = inputs**2.0\n        mean_values = backend.mean(values, axis=-1, keepdims=True)\n        mean_values += 1.0e-8\n        l2 = backend.sqrt(mean_values)\n        normalized = inputs / l2\n        return normalized\n \n    # define the output shape of the layer\n    def compute_output_shape(self, input_shape):\n        return input_shape","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.798295Z","iopub.status.busy":"2024-02-29T04:21:32.797957Z","iopub.status.idle":"2024-02-29T04:21:32.835142Z","shell.execute_reply":"2024-02-29T04:21:32.834120Z","shell.execute_reply.started":"2024-02-29T04:21:32.798263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mini-batch standard deviation layer\nclass MinibatchStdev(Layer):\n    # initialize the layer\n    def __init__(self, **kwargs):\n        super(MinibatchStdev, self).__init__(**kwargs)\n \n    # perform the operation\n    def call(self, inputs):\n        mean = backend.mean(inputs, axis=0, keepdims=True)\n        squ_diffs = backend.square(inputs - mean)\n        mean_sq_diff = backend.mean(squ_diffs, axis=0, keepdims=True)\n        mean_sq_diff += 1e-8\n        stdev = backend.sqrt(mean_sq_diff)\n        \n        mean_pix = backend.mean(stdev, keepdims=True)\n        shape = backend.shape(inputs)\n        output = backend.tile(mean_pix, (shape[0], shape[1], shape[2], 1))\n        \n        combined = backend.concatenate([inputs, output], axis=-1)\n        return combined\n \n    # define the output shape of the layer\n    def compute_output_shape(self, input_shape):\n        input_shape = list(input_shape)\n        input_shape[-1] += 1\n        return tuple(input_shape)","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.836747Z","iopub.status.busy":"2024-02-29T04:21:32.836419Z","iopub.status.idle":"2024-02-29T04:21:32.846310Z","shell.execute_reply":"2024-02-29T04:21:32.845187Z","shell.execute_reply.started":"2024-02-29T04:21:32.836723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# weighted sum output\nclass WeightedSum(Add):\n    # init with default value\n    def __init__(self, alpha=0.0, **kwargs):\n        super(WeightedSum, self).__init__(**kwargs)\n        self.alpha = backend.variable(alpha, name='ws_alpha')\n \n    # output a weighted sum of inputs\n    def _merge_function(self, inputs):\n        # only supports a weighted sum of two inputs\n        assert (len(inputs) == 2)\n        # ((1-a) * input1) + (a * input2)\n        output = ((1.0 - self.alpha) * inputs[0]) + (self.alpha * inputs[1])\n        return output\n\n# calculate wasserstein loss\ndef wasserstein_loss(y_true, y_pred):\n    return backend.mean(y_true * y_pred)","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.847823Z","iopub.status.busy":"2024-02-29T04:21:32.847483Z","iopub.status.idle":"2024-02-29T04:21:32.860781Z","shell.execute_reply":"2024-02-29T04:21:32.860061Z","shell.execute_reply.started":"2024-02-29T04:21:32.847793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model helper functions","metadata":{}},{"cell_type":"code","source":"import tqdm\n# load dataset\ndef load_images(directory):\n    faces = list()\n    for filename in tqdm.tqdm(listdir(directory)):\n        face = Image.open(directory + filename)\n        face = asarray(face)\n        faces.append(face)\n    \n    faces = asarray(faces)\n    faces = faces.astype('float32')\n    faces = (faces - 127.5) / 127.5\n    \n    return faces\n \n# select real samples\ndef generate_real_samples(dataset, n_samples):\n    ix = randint(0, dataset.shape[0], n_samples)\n    X = dataset[ix]\n    y = ones((n_samples, 1))\n    return X, y\n \n# generate points in latent space as input for the generator\ndef generate_latent_points(latent_dim, n_samples):\n    x_input = randn(latent_dim * n_samples)\n    x_input = x_input.reshape(n_samples, latent_dim)\n    return x_input\n \n# use the generator to generate n fake examples, with class labels\ndef generate_fake_samples(generator, latent_dim, n_samples):\n    x_input = generate_latent_points(latent_dim, n_samples)\n    X = generator.predict(x_input, verbose=0)\n    y = -ones((n_samples, 1))\n    return X, y\n \n# update the alpha value on each instance of WeightedSum\ndef update_fadein(models, step, n_steps):\n    alpha = step / float(n_steps - 1)\n    for model in models:\n        for layer in model.layers:\n            if isinstance(layer, WeightedSum):\n                backend.set_value(layer.alpha, alpha)\n                \n# scale images to preferred size\ndef scale_dataset(images, new_shape):\n    images_list = list()\n    for image in images:\n        new_image = resize(image, new_shape, 0)\n        images_list.append(new_image)\n    return asarray(images_list)","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.862002Z","iopub.status.busy":"2024-02-29T04:21:32.861712Z","iopub.status.idle":"2024-02-29T04:21:32.874515Z","shell.execute_reply":"2024-02-29T04:21:32.873603Z","shell.execute_reply.started":"2024-02-29T04:21:32.861970Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a equalized learning rate layer that inherits from the Conv2D layer\nclass EqualizedConv2D(Conv2D):\n    def __init__(self, *args, **kwargs):\n        kwargs['kernel_initializer'] = kwargs.get('kernel_initializer', RandomNormal(0, 1))\n        super(EqualizedConv2D, self).__init__(*args, **kwargs)\n \n    def build(self, input_shape):\n        super(EqualizedConv2D, self).build(input_shape)\n        input_channels = input_shape[-1]\n        kernel_size = self.kernel_size[0]\n        self.lr_multiplier = (2 / (input_channels * (kernel_size ** 2))) ** 0.5\n \n    # apply the learning rate multiplier\n    def call(self, inputs):\n        # Scale the weights without permanently modifying them\n        scaled_weights = self.lr_multiplier * self.kernel\n        outputs = self.convolution_op(inputs, scaled_weights)\n        if self.use_bias:\n            outputs = tf.nn.bias_add(outputs, self.bias)\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs\n    \n# Create a equalized learning rate layer that inherits from the Dense layer\nclass EqualizedDense(Dense):\n    def __init__(self, *args, **kwargs):\n        kwargs['kernel_initializer'] = kwargs.get('kernel_initializer', RandomNormal(0, 1))\n        super(EqualizedDense, self).__init__(*args, **kwargs)\n \n    def build(self, input_shape):\n        super(EqualizedDense, self).build(input_shape)\n        input_channels = input_shape[-1]\n        self.lr_multiplier = (2 / input_channels) ** 0.5\n \n    # apply the learning rate multiplier\n    def call(self, inputs):\n        # Scale the weights without permanently modifying them\n        scaled_weights = self.lr_multiplier * self.kernel\n        outputs = tf.matmul(inputs, scaled_weights)\n        if self.use_bias:\n            outputs = backend.bias_add(outputs, self.bias)\n        if self.activation is not None:\n            return self.activation(outputs)\n        return outputs","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.876288Z","iopub.status.busy":"2024-02-29T04:21:32.875810Z","iopub.status.idle":"2024-02-29T04:21:32.888630Z","shell.execute_reply":"2024-02-29T04:21:32.887799Z","shell.execute_reply.started":"2024-02-29T04:21:32.876258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model creation","metadata":{}},{"cell_type":"code","source":"# adding a generator block\ndef add_generator_block(old_model, filter_count, channels):\n    block_end = old_model.layers[-2].output\n    \n    # upsample, and define new block\n    upsampling = UpSampling2D()(block_end)\n    g = EqualizedConv2D(filter_count, (3,3), padding='same')(upsampling)\n    g = PixelNormalization()(g)\n    g = LeakyReLU(alpha=0.2)(g)\n    g = EqualizedConv2D(filter_count, (3,3), padding='same')(g)\n    g = PixelNormalization()(g)\n    g = LeakyReLU(alpha=0.2)(g)\n    \n    out_image = EqualizedConv2D(channels, (1,1), padding='same')(g)\n    model1 = Model(old_model.input, out_image)\n    out_old = old_model.layers[-1]\n    out_image2 = out_old(upsampling)\n    \n    merged = WeightedSum()([out_image2, out_image])\n    model2 = Model(old_model.input, merged)\n    return [model1, model2]","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.891650Z","iopub.status.busy":"2024-02-29T04:21:32.891385Z","iopub.status.idle":"2024-02-29T04:21:32.900853Z","shell.execute_reply":"2024-02-29T04:21:32.899947Z","shell.execute_reply.started":"2024-02-29T04:21:32.891625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define generator models\ndef define_generator(latent_dim, n_blocks, initial_filter_count, in_dim=4, channels=3):\n    model_list = list()\n    \n    in_latent = Input(shape=(latent_dim,))\n    g = EqualizedDense(initial_filter_count * in_dim * in_dim)(in_latent)\n    g = Reshape((in_dim, in_dim, initial_filter_count))(g)\n    \n    # conv 4x4, input block\n    g = EqualizedConv2D(initial_filter_count, (4,4), padding='same')(g)\n    g = PixelNormalization()(g)\n    g = LeakyReLU(alpha=0.2)(g)\n    \n    # conv 3x3\n    g = EqualizedConv2D(initial_filter_count, (3,3), padding='same')(g)\n    g = PixelNormalization()(g)\n    g = LeakyReLU(alpha=0.2)(g)\n    \n    # conv 1x1, output block\n    out_image = EqualizedConv2D(channels, (1,1), padding='same')(g)\n    model = Model(in_latent, out_image)\n    model_list.append([model, model])\n    \n    for i in range(1, n_blocks):\n        old_model = model_list[i - 1][0]\n        models = add_generator_block(old_model, initial_filter_count, channels)# // (2 ** i))\n        model_list.append(models)\n        \n    return model_list","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.902273Z","iopub.status.busy":"2024-02-29T04:21:32.901903Z","iopub.status.idle":"2024-02-29T04:21:32.915127Z","shell.execute_reply":"2024-02-29T04:21:32.914286Z","shell.execute_reply.started":"2024-02-29T04:21:32.902202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding a discriminator block\ndef add_discriminator_block(old_model, filter_count, n_input_layers=3):\n    in_shape = list(old_model.input.shape)\n    \n    # define new input shape as double the size\n    input_shape = (in_shape[-2]*2, in_shape[-2]*2, in_shape[-1])\n    in_image = Input(shape=input_shape)\n    \n    # define new input processing layer\n    d = EqualizedConv2D(filter_count, (1,1), padding='same')(in_image)\n    d = LeakyReLU(alpha=0.2)(d)\n    \n    # define new block\n    d = EqualizedConv2D(filter_count, (3, 3), padding='same')(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    # d = Conv2D(filter_count * 2, (3,3), padding='same', kernel_initializer=init, kernel_constraint=const)(d)\n    # d = EqualizedConv2D(filter_count, (3, 3), strides=2, padding='same')(d)\n    d = EqualizedConv2D(filter_count, (3, 3), padding='same')(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = AveragePooling2D()(d)\n    block_new = d\n    \n    # skip the input, 1x1 and activation for the old model\n    for i in range(n_input_layers, len(old_model.layers)):\n        d = old_model.layers[i](d)\n    model1 = Model(in_image, d)\n    \n    model1.compile(loss=wasserstein_loss, optimizer=Adam(**adam_config))\n    \n    downsample = AveragePooling2D()(in_image)\n    \n    block_old = old_model.layers[1](downsample)\n    block_old = old_model.layers[2](block_old)\n    d = WeightedSum()([block_old, block_new])\n    \n    for i in range(n_input_layers, len(old_model.layers)):\n        d = old_model.layers[i](d)\n        \n    model2 = Model(in_image, d)\n    \n    model2.compile(loss=wasserstein_loss, optimizer=Adam(**adam_config))\n    return [model1, model2]","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.916902Z","iopub.status.busy":"2024-02-29T04:21:32.916351Z","iopub.status.idle":"2024-02-29T04:21:32.927580Z","shell.execute_reply":"2024-02-29T04:21:32.926769Z","shell.execute_reply.started":"2024-02-29T04:21:32.916870Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the discriminator models for each image resolution\ndef define_discriminator(n_blocks, initial_filter_count, input_shape=(4,4,3)):\n    model_list = list()\n    in_image = Input(shape=input_shape)\n    \n    d = EqualizedConv2D(initial_filter_count, (1, 1), padding='same')(in_image)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = MinibatchStdev()(d)\n    \n    d = EqualizedConv2D(initial_filter_count, (3, 3), padding='same')(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = EqualizedConv2D(initial_filter_count, (4, 4), padding='same')(d)\n    d = LeakyReLU(alpha=0.2)(d)\n    \n    d = Flatten()(d)\n    out_class = EqualizedDense(1)(d)\n    \n    model = Model(in_image, out_class)\n    model.compile(loss=wasserstein_loss, optimizer=Adam(**adam_config))\n    model_list.append([model, model])\n    \n    for i in range(1, n_blocks):\n        old_model = model_list[i - 1][0]\n        models = add_discriminator_block(old_model, initial_filter_count)# / (2 ** i))\n        model_list.append(models)\n        \n    return model_list","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.928857Z","iopub.status.busy":"2024-02-29T04:21:32.928565Z","iopub.status.idle":"2024-02-29T04:21:32.940698Z","shell.execute_reply":"2024-02-29T04:21:32.939948Z","shell.execute_reply.started":"2024-02-29T04:21:32.928835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define composite models for training generators via discriminators\n\ndef define_composite(discriminators, generators):\n    model_list = list()\n    # create composite models\n    for i in range(len(discriminators)):\n        g_models, d_models = generators[i], discriminators[i]\n        # straight-through model\n        d_models[0].trainable = False\n        model1 = Sequential()\n        model1.add(g_models[0])\n        model1.add(d_models[0])\n        model1.compile(loss=wasserstein_loss, optimizer=Adam(**adam_config))\n        # fade-in model\n        d_models[1].trainable = False\n        model2 = Sequential()\n        model2.add(g_models[1])\n        model2.add(d_models[1])\n        model2.compile(loss=wasserstein_loss, optimizer=Adam(**adam_config))\n        # store\n        model_list.append([model1, model2])\n    return model_list","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:21:32.941904Z","iopub.status.busy":"2024-02-29T04:21:32.941636Z","iopub.status.idle":"2024-02-29T04:21:32.954476Z","shell.execute_reply":"2024-02-29T04:21:32.953577Z","shell.execute_reply.started":"2024-02-29T04:21:32.941884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create training block","metadata":{}},{"cell_type":"code","source":"# train a generator and discriminator\ndef train_epochs(g_model, d_model, gan_model, dataset, n_epochs, n_batch, fadein=False):\n    bat_per_epo = int(dataset.shape[0] / n_batch)\n    n_steps = bat_per_epo * n_epochs\n    half_batch = int(n_batch / 2)\n    d_loss1_avg = 0\n    d_loss2_avg = 0\n    g_loss_avg = 0\n    \n    for i in range(n_steps):\n        # update alpha for all WeightedSum layers when fading in new blocks\n        if fadein:\n            update_fadein([g_model, d_model, gan_model], i, n_steps)\n        # prepare real and fake samples\n        X_real, y_real = generate_real_samples(dataset, half_batch)\n        X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)\n        \n        # update discriminator model\n        d_loss1 = d_model.train_on_batch(X_real, y_real)\n        d_loss2 = d_model.train_on_batch(X_fake, y_fake)\n        \n        d_loss1_avg += d_loss1\n        d_loss2_avg += d_loss2\n        \n        # update the generator via the discriminator's error\n        z_input = generate_latent_points(latent_dim, n_batch)\n        y_real2 = ones((n_batch, 1))\n        g_loss = gan_model.train_on_batch(z_input, y_real2)\n        g_loss_avg += g_loss\n        \n        if i % 100 == 0:\n            print('Step:%d | Avg Loss: d_loss_real=%.3f, d_loss_fake=%.3f g=%.3f' % (i+1, d_loss1_avg/100, d_loss2_avg/100, g_loss_avg/100))\n            d_loss1_avg = 0\n            d_loss2_avg = 0\n            g_loss_avg = 0\n        \n        if i % 1000 == 0:\n            # Plot some samples\n            X, _ = generate_fake_samples(g_model, latent_dim, 12)\n            X = (X - X.min()) / (X.max() - X.min())\n            \n            plt.figure(figsize=(8, 3))\n            for i in range(12):\n                plt.subplot(2, 6, 1 + i)\n                plt.axis('off')\n                img_show = X[i]\n                plt.imshow(img_show)\n                \n            plt.show()\n            \n        \n# train the generator and discriminator\ndef train(g_models, d_models, gan_models, dataset, latent_dim, e_norm, e_fadein, n_batch):\n    g_normal, d_normal, gan_normal = g_models[0][0], d_models[0][0], gan_models[0][0]\n    gen_shape = g_normal.output_shape\n    scaled_data = scale_dataset(dataset, gen_shape[1:])\n    print('Scaled Data', scaled_data.shape)\n\n    # train normal or straight-through models\n    train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[0], n_batch[0])\n    summarize_performance('tuned', g_normal, d_normal, latent_dim)\n    \n    # process each level of growth\n    for i in range(1, len(g_models)):\n        # retrieve models for this level of growth\n        [g_normal, g_fadein] = g_models[i]\n        [d_normal, d_fadein] = d_models[i]\n        [gan_normal, gan_fadein] = gan_models[i]\n        \n        # scale dataset to appropriate size\n        gen_shape = g_normal.output_shape\n        scaled_data = scale_dataset(dataset, gen_shape[1:])\n        print('Scaled Data', scaled_data.shape)\n        \n        # train fade-in models for next level of growth\n        train_epochs(g_fadein, d_fadein, gan_fadein, scaled_data, e_fadein[i], n_batch[i], True)\n        summarize_performance('faded', g_fadein, d_fadein, latent_dim)\n        \n        # train normal or straight-through models\n        train_epochs(g_normal, d_normal, gan_normal, scaled_data, e_norm[i], n_batch[i])\n        summarize_performance('tuned', g_normal, d_normal, latent_dim)","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:30:19.615238Z","iopub.status.busy":"2024-02-29T04:30:19.614850Z","iopub.status.idle":"2024-02-29T04:30:19.633472Z","shell.execute_reply":"2024-02-29T04:30:19.632362Z","shell.execute_reply.started":"2024-02-29T04:30:19.615205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# generate samples and save as a plot and save the model\ndef summarize_performance(status, g_model, d_model, latent_dim, n_samples=25):\n    gen_shape = g_model.output_shape\n    name = '%03dx%03d-%s' % (gen_shape[1], gen_shape[2], status)\n    \n    X, _ = generate_fake_samples(g_model, latent_dim, n_samples)\n    X = (X - X.min()) / (X.max() - X.min())\n    \n    square = int(sqrt(n_samples))\n    for i in range(n_samples):\n        plt.subplot(square, square, 1 + i)\n        plt.axis('off')\n        img_show = X[i]\n        plt.imshow(img_show)\n        \n    # save plot to file\n    if not os.path.exists('plots'):\n        os.makedirs('plots')\n    plot_filename = 'plots/plot_%s.png' % (name)\n    plt.savefig(plot_filename)\n    plt.close()\n    \n    if not os.path.exists('models'):\n        os.makedirs('models')\n    g_model_filename = 'models/model_%s.h5' % (name)\n    g_model.save(g_model_filename)\n    d_model_filename = 'models/d_model_%s.h5' % (name)\n    d_model.save(d_model_filename)\n    print('>Saved: %s, %s and %s' % (plot_filename, g_model_filename, d_model_filename))","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:30:19.723238Z","iopub.status.busy":"2024-02-29T04:30:19.722609Z","iopub.status.idle":"2024-02-29T04:30:19.731527Z","shell.execute_reply":"2024-02-29T04:30:19.730624Z","shell.execute_reply.started":"2024-02-29T04:30:19.723210Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run training","metadata":{}},{"cell_type":"code","source":"# Load all the images of face_images_32x32\ndirectory = '/kaggle/input/ffhq-32x32/face_images_32x32/'\ndataset = load_images(directory)\n\ndataset = dataset[:, :, :, :3]","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:22:46.323849Z","iopub.status.busy":"2024-02-29T04:22:46.323501Z","iopub.status.idle":"2024-02-29T04:28:28.567396Z","shell.execute_reply":"2024-02-29T04:28:28.566385Z","shell.execute_reply.started":"2024-02-29T04:22:46.323821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_blocks = 4\ninitial_filter_count = 256\nlatent_dim = 128\n\nn_batch = [16, 16, 16, 16]\nn_epochs = [4, 5, 8, 11]\n\nd_models = define_discriminator(n_blocks, initial_filter_count, input_shape=(4,4,3))\ng_models = define_generator(latent_dim, n_blocks, initial_filter_count, channels=3)\ngan_models = define_composite(d_models, g_models)\n","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:30:23.672169Z","iopub.status.busy":"2024-02-29T04:30:23.671452Z","iopub.status.idle":"2024-02-29T04:30:25.972240Z","shell.execute_reply":"2024-02-29T04:30:25.971471Z","shell.execute_reply.started":"2024-02-29T04:30:23.672124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train(g_models, d_models, gan_models, dataset, latent_dim, n_epochs, n_epochs, n_batch)","metadata":{"execution":{"iopub.execute_input":"2024-02-29T04:32:13.343772Z","iopub.status.busy":"2024-02-29T04:32:13.342918Z","iopub.status.idle":"2024-02-29T04:35:56.781903Z","shell.execute_reply":"2024-02-29T04:35:56.780335Z","shell.execute_reply.started":"2024-02-29T04:32:13.343726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}